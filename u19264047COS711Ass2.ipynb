{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2803 entries, 0 to 2802\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                2803 non-null   int64  \n",
      " 1   Length (major axis)       1946 non-null   float64\n",
      " 2   Width (minor axis)        1861 non-null   float64\n",
      " 3   Thickness (depth)         1799 non-null   float64\n",
      " 4   Area                      2803 non-null   float64\n",
      " 5   Perimeter                 2803 non-null   float64\n",
      " 6   Roundness                 1946 non-null   float64\n",
      " 7   Solidity                  2803 non-null   float64\n",
      " 8   Compactness               2803 non-null   float64\n",
      " 9   Aspect Ratio              1004 non-null   float64\n",
      " 10  Eccentricity              1004 non-null   float64\n",
      " 11  Extent                    2803 non-null   float64\n",
      " 12  Convex hull(convex area)  2803 non-null   float64\n",
      " 13  Type                      2803 non-null   object \n",
      "dtypes: float64(12), int64(1), object(1)\n",
      "memory usage: 306.7+ KB\n",
      "   Unnamed: 0  Length (major axis)  Width (minor axis)  Thickness (depth)  \\\n",
      "0           0                  NaN          227.940628         127.759132   \n",
      "1           1                  NaN          234.188126         128.199509   \n",
      "2           2                  NaN          229.418610         125.796547   \n",
      "3           3                  NaN          232.763153         125.918808   \n",
      "4           4                  NaN          230.150742         107.253448   \n",
      "\n",
      "      Area   Perimeter  Roundness  Solidity  Compactness  Aspect Ratio  \\\n",
      "0  22619.0  643.813269        NaN  0.973384     1.458265           NaN   \n",
      "1  23038.0  680.984841        NaN  0.957304     1.601844           NaN   \n",
      "2  22386.5  646.943212        NaN  0.967270     1.487772           NaN   \n",
      "3  22578.5  661.227483        NaN  0.965512     1.540979           NaN   \n",
      "4  19068.0  624.842706        NaN  0.951450     1.629395           NaN   \n",
      "\n",
      "   Eccentricity    Extent  Convex hull(convex area)   Type  \n",
      "0           NaN  0.681193                   23237.5  MAMRA  \n",
      "1           NaN  0.656353                   24065.5  MAMRA  \n",
      "2           NaN  0.683620                   23144.0  MAMRA  \n",
      "3           NaN  0.685360                   23385.0  MAMRA  \n",
      "4           NaN  0.714800                   20041.0  MAMRA  \n",
      "Invalid value found: 1.0000000000000004 at row 1234, column 'Eccentricity'\n"
     ]
    }
   ],
   "source": [
    "file_path = 'almonds/Almond.csv'\n",
    "almond_data = pd.read_csv(file_path)\n",
    "\n",
    "almond_data.info(), print(almond_data.head())\n",
    "\n",
    "almond_data_cleaned = almond_data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "features = almond_data_cleaned.drop(columns=['Type'])\n",
    "target = almond_data_cleaned['Type']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_normalized = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
    "\n",
    "features_normalized_filled = features_normalized.fillna(-1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "target_encoded_filled = pd.DataFrame(encoder.fit_transform(target.values.reshape(-1, 1)), columns=encoder.categories_[0])\n",
    "\n",
    "preprocessed_data_filled = pd.concat([features_normalized_filled, target_encoded_filled], axis=1)\n",
    "\n",
    "for index, row in preprocessed_data_filled.iterrows():\n",
    "        for col in preprocessed_data_filled.columns:\n",
    "            value = row[col]\n",
    "            if not (0 <= value <= 1 or value == -1):\n",
    "                print(f\"Invalid value found: {value} at row {index}, column '{col}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_file_path = 'almonds/Almond_Prepped.csv'\n",
    "preprocessed_data_filled.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length (major axis)  Width (minor axis)  Thickness (depth)      Area  \\\n",
      "837              0.442068           -1.000000           0.456272  0.267524   \n",
      "1921            -1.000000            0.260692           0.355551  0.056250   \n",
      "1573             0.326015           -1.000000           0.089350  0.089309   \n",
      "2724            -1.000000            0.436433           0.685816  0.148147   \n",
      "1982             0.489893           -1.000000           0.664943  0.353583   \n",
      "318              0.414994            0.592607          -1.000000  0.451685   \n",
      "124              0.696864            0.828816          -1.000000  0.761812   \n",
      "2342            -1.000000            0.287797           0.381158  0.064340   \n",
      "354              0.124878            0.224931          -1.000000  0.158850   \n",
      "1454             0.329117           -1.000000           0.226752  0.129683   \n",
      "\n",
      "      Perimeter  Roundness  Solidity  Compactness  Aspect Ratio  Eccentricity  \\\n",
      "837    0.328293   0.374171  0.920623     0.086263     -1.000000     -1.000000   \n",
      "1921   0.068669  -1.000000  0.926302     0.015780     -1.000000     -1.000000   \n",
      "1573   0.185391   0.117509  0.673978     0.112867     -1.000000     -1.000000   \n",
      "2724   0.144373  -1.000000  0.949623     0.009337     -1.000000     -1.000000   \n",
      "1982   0.336514   0.461883  0.950600     0.046741     -1.000000     -1.000000   \n",
      "318    0.376416   0.828651  0.917019     0.035368      0.149538      0.348813   \n",
      "124    0.736040   0.697879  0.755412     0.148412      0.274627      0.538702   \n",
      "2342   0.071400  -1.000000  0.946689     0.009677     -1.000000     -1.000000   \n",
      "354    0.153165   0.877628  0.975048     0.009773      0.117759      0.288442   \n",
      "1454   0.255670   0.224957  0.692373     0.142441     -1.000000     -1.000000   \n",
      "\n",
      "        Extent  Convex hull(convex area)  MAMRA  REGULAR  SANORA  \n",
      "837   0.734164                  0.270426    0.0      0.0     1.0  \n",
      "1921  0.771039                  0.055352    0.0      1.0     0.0  \n",
      "1573  0.569325                  0.101498    1.0      0.0     0.0  \n",
      "2724  0.773909                  0.147199    0.0      0.0     1.0  \n",
      "1982  0.769075                  0.354311    0.0      1.0     0.0  \n",
      "318   0.707370                  0.458259    0.0      0.0     1.0  \n",
      "124   0.631678                  0.814617    1.0      0.0     0.0  \n",
      "2342  0.750428                  0.062773    0.0      1.0     0.0  \n",
      "354   0.760567                  0.156346    0.0      0.0     1.0  \n",
      "1454  0.683069                  0.144405    1.0      0.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "Prepped_file_path = 'almonds/Almond_Prepped.csv'\n",
    "preprocessed_data_filled = pd.read_csv(Prepped_file_path)\n",
    "print(preprocessed_data_filled.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data_filled.drop(columns=['MAMRA', 'REGULAR', 'SANORA']).values\n",
    "Y = preprocessed_data_filled[['MAMRA', 'REGULAR', 'SANORA']].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split(X_train, Y_train, test_size=0.375, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_eval_tensor = torch.tensor(X_eval, dtype=torch.float32)\n",
    "Y_eval_tensor = torch.tensor(Y_eval, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "eval_dataset = TensorDataset(X_eval_tensor, Y_eval_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size, actFunc = 'ReLU'):\n",
    "        super(NN, self).__init__()\n",
    "        self.inputLayer = nn.Linear(input_size, hidden_layers[0])\n",
    "        self.hiddenLayers = []\n",
    "        for i in range(len(hidden_layers)-1):\n",
    "            self.hiddenLayers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "        self.outputLayer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        self.actFunc = nn.ReLU()\n",
    "        if (actFunc == 'Sigmoid'):\n",
    "            self.actFunc = nn.Sigmoid()\n",
    "        if (actFunc == 'TanH'):\n",
    "            self.actFunc = nn.Tanh()\n",
    "        if (actFunc == 'TanH'):\n",
    "            self.actFunc = nn.Tanh()\n",
    "        if (actFunc == 'TanH'):\n",
    "            self.actFunc = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.actFunc(self.inputLayer(x))\n",
    "        for layer in self.hiddenLayers:\n",
    "            x = self.actFunc(layer(x))\n",
    "        x = self.outputLayer(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(optimizer, model, loader, num_epochs, verbose = 1):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if(verbose == 1):\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(loader):.4f}')\n",
    "\n",
    "def test_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            labels_class = torch.max(labels, 1)[1]\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels_class).sum().item()\n",
    "    accuracy = 100 * (correct / total)\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1040\n",
      "Epoch [2/20], Loss: 1.1004\n",
      "Epoch [3/20], Loss: 1.0986\n",
      "Epoch [4/20], Loss: 1.0962\n",
      "Epoch [5/20], Loss: 1.0960\n",
      "Epoch [6/20], Loss: 1.0948\n",
      "Epoch [7/20], Loss: 1.0914\n",
      "Epoch [8/20], Loss: 1.0894\n",
      "Epoch [9/20], Loss: 1.0856\n",
      "Epoch [10/20], Loss: 1.0783\n",
      "Epoch [11/20], Loss: 1.0757\n",
      "Epoch [12/20], Loss: 1.0695\n",
      "Epoch [13/20], Loss: 1.0628\n",
      "Epoch [14/20], Loss: 1.0585\n",
      "Epoch [15/20], Loss: 1.0519\n",
      "Epoch [16/20], Loss: 1.0468\n",
      "Epoch [17/20], Loss: 1.0414\n",
      "Epoch [18/20], Loss: 1.0360\n",
      "Epoch [19/20], Loss: 1.0322\n",
      "Epoch [20/20], Loss: 1.0306\n",
      "Test Accuracy: 50.80%\n"
     ]
    }
   ],
   "source": [
    "def simulate(hiddenLayers, activationFunction, train_loader, eval_loader, epochs = 20):\n",
    "    input_size = 12\n",
    "    output_size = 3\n",
    "    \n",
    "    hidden_size = [4]\n",
    "    for _ in range(hiddenLayers - 1):\n",
    "        next_number = hidden_size[0] * 2\n",
    "        hidden_size.insert(0, next_number)\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    model = NN(input_size, hidden_size, output_size, activationFunction)\n",
    "    optimizer_adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_model(optimizer_adam, model, train_loader, epochs, verbose=0)\n",
    "    test_model(model, eval_loader)\n",
    "\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
